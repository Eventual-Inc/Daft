"""
Text Embedding Project
Generated by Daft CLI
"""

import daft
from daft.functions import embed_text


def main():
    # Load data
    {% if data_source == "CSV" %}
    df = daft.read_csv("{{ data_source_path }}")
    {% elif data_source == "JSONL" %}
    df = daft.read_json("{{ data_source_path }}")
    {% elif data_source == "Parquet" %}
    df = daft.read_parquet("{{ data_source_path }}")
    {% elif data_source == "Huggingface" %}
    df = daft.read_huggingface("{{ data_source_path }}")
    {% elif data_source == "Raw Files" %}
    df = daft.from_glob_path("{{ data_source_path }}")
    # Create content column from file paths
    df = df.with_column("content", df["path"].download().cast(str))
    {% else %}
    # TODO: Load your data here
    # Example: df = daft.read_csv("path/to/your/data.csv")
    df = None
    {% endif %}

    # Generate embeddings
    df = df.with_column(
        "{{ output_column }}",
        embed_text(df["{{ selected_columns[0] }}"])
    )

    # Write output
    {% if output_data_source == "Parquet" %}
    df.write_parquet("output.parquet", write_mode="overwrite")
    {% elif output_data_source == "CSV" %}
    df.write_csv("output.csv", write_mode="overwrite")
    {% elif output_data_source == "JSON" %}
    df.write_json("output.json", write_mode="overwrite")
    {% elif output_data_source == "Turbopuffer" %}
    # Prepare dataframe for Turbopuffer: id and vector columns
    df = df.select(
        df["{{ selected_columns[0] }}"].cast(str).alias("id"),
        df["{{ output_column }}"].alias("vector")
    )
    # TODO: Configure Turbopuffer namespace and API key
    df.write_turbopuffer("your_namespace", api_key="your_api_key")
    {% elif output_data_source == "Iceberg" %}
    # TODO: Configure Iceberg table
    # df.write_iceberg(table, mode="append")
    {% elif output_data_source == "Delta Lake" %}
    df.write_deltalake("output_path", mode="overwrite")
    {% elif output_data_source == "Lance" %}
    df.write_lance("output.lance", mode="overwrite")
    {% elif output_data_source == "Clickhouse" %}
    # TODO: Configure Clickhouse connection
    # df.write_clickhouse("table_name", host="localhost", port=8123)
    {% elif output_data_source == "Huggingface" %}
    df.write_huggingface("your_username/your_repo")
    {% elif output_data_source == "Bigtable" %}
    # TODO: Configure Bigtable connection
    # df.write_bigtable(project_id="project", instance_id="instance", table_id="table", row_key_column="id")
    {% endif %}


if __name__ == "__main__":
    main()
