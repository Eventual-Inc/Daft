name: Build a Daft commit and store the outputted wheel in AWS S3

on:
  workflow_dispatch:
    inputs:
      x86:
        description: Build for x86
        required: false
        default: false
      arm:
        description: Build for ARM
        required: false
        default: false
  workflow_call:
    secrets:
      ACTIONS_AWS_ROLE_ARN:
        description: The ARN of the AWS role to assume
        required: true
    inputs:
      commit:
        type: string
        description: The commit hash to build
        required: true
    outputs:
      wheel:
        description: The wheel file that was built
        value: ${{ jobs.build-commit.outputs.wheel }}

jobs:
  build-commit:
    strategy:
      fail-fast: false
      matrix:
        compile_arch: [x86, arm]
    runs-on: buildjet-8vcpu-ubuntu-2004
    timeout-minutes: 15 # Remove for ssh debugging
    permissions:
      id-token: write
      contents: read
    outputs:
      wheel: ${{ steps.build_and_upload.outputs.wheel }}
    steps:
    - if: ${{ (matrix.compile_arch == 'x86') && (github.event.inputs.x86 == 'false') }}
      run: exit 0
    - if: ${{ (matrix.compile_arch == 'arm') && (github.event.inputs.arm == 'false') }}
      run: exit 0
    - uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-region: us-west-2
        role-to-assume: ${{ secrets.ACTIONS_AWS_ROLE_ARN }}
        role-session-name: daft-performance-comparisons-build
    - uses: actions/checkout@v4
      with:
        ref: ${{ inputs.commit || github.sha }}
        fetch-depth: 1
    - uses: ./.github/actions/install
    - uses: buildjet/cache@v4
      with:
        path: ~/target
        key: ${{ runner.os }}-cargo-deps-${{ hashFiles('**/Cargo.lock') }}
        restore-keys: ${{ runner.os }}-cargo-deps-
    - name: Build the python wheel and upload it to AWS S3
      id: build_and_upload
      run: |
        if ! ls ~/target/wheels/*.whl 1> /dev/null 2>&1; then
          # Build wheel
          export CARGO_TARGET_DIR=~/target
          uv v
          source .venv/bin/activate
          uv pip install pip maturin
          maturin build --release
        fi

        # Upload wheel
        # (there should only be one output wheel in this directory)
        for file in ~/target/wheels/*.whl; do
          aws s3 cp $file s3://github-actions-artifacts-bucket/builds/${{ inputs.commit || github.sha }}/ --acl public-read --no-progress;
          file_basename=$(basename $file)
          echo "wheel=$file_basename" >> $GITHUB_OUTPUT
          echo "Output wheel has been built and stored in S3 at the following location:" >> $GITHUB_STEP_SUMMARY
          echo "https://us-west-2.console.aws.amazon.com/s3/buckets/github-actions-artifacts-bucket?prefix=builds/${{ inputs.commit || github.sha }}/" >> $GITHUB_STEP_SUMMARY
        done
