name: daft-publish

on:
  schedule:
  #        ┌───────────── minute (0 - 59)
  #        │  ┌───────────── hour (0 - 23)
  #        │  │ ┌───────────── day of the month (1 - 31)
  #        │  │ │ ┌───────────── month (1 - 12 or JAN-DEC)
  #        │  │ │ │ ┌───────────── day of the week (0 - 6 or SUN-SAT)
  #        │  │ │ │ │
  - cron: 0 5 * * *

  push:
    tags:
    - v*
  workflow_dispatch:

env:
  PACKAGE_NAME: getdaft
  PYTHON_VERSION: '3.7' # to build abi3 wheels

jobs:
  build-and-test:

    name: platform wheels for ${{ matrix.os }}
    runs-on: ${{ matrix.os }}-latest
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu, macos]
    steps:
    - uses: actions/checkout@v3
      with:
        submodules: true
        fetch-depth: 0
    - uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        architecture: x64
    - run: pip install -U twine toml
    - run: python tools/patch_package_version.py
    - name: Install Rust toolchain
      uses: actions-rs/toolchain@v1
      with:
        toolchain: stable
        profile: minimal
        default: true

    - name: Build wheels - x86_64
      uses: messense/maturin-action@v1
      with:
        target: x86_64
        args: --release --out dist --sdist

    - name: Build wheels - arm64
      uses: messense/maturin-action@v1
      with:
        target: aarch64
        args: --release --out dist

    - name: Install and test built wheel - x86_64
      run: |
        pip install -r requirements-dev.txt
        pip install dist/${{ env.PACKAGE_NAME }}-*-cp37-*.whl --force-reinstall
        rm -rf daft
        pytest -v

    - name: Upload wheels
      uses: actions/upload-artifact@v2
      with:
        name: wheels
        path: dist


  #   - name: Publish bdist package to PYPI
  #     if: ${{ success() && (env.IS_PUSH == 'true') }}
  #     run: python -m twine upload --skip-existing --disable-progress-bar ./wheelhouse/*
  #     env:
  #       TWINE_USERNAME: __token__
  #       TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
  #   - uses: conda-incubator/setup-miniconda@v2
  #     with:
  #       auto-update-conda: true
  #       # Really doesn't matter what version we upload with
  #       # just the version we test with
  #       python-version: '3.8'
  #       channels: conda-forge
  #       channel-priority: true
  #       mamba-version: '*'

  #   - name: Install anaconda client
  #     shell: bash -el {0}
  #     run: conda install -q -y anaconda-client

  #   - name: Upload wheels to anaconda nightly
  #     if: ${{ success() && (env.IS_SCHEDULE_DISPATCH == 'true' || env.IS_PUSH == 'true') }}
  #     shell: bash -el {0}
  #     env:
  #       DAFT_STAGING_UPLOAD_TOKEN: ${{ secrets.DAFT_STAGING_UPLOAD_TOKEN }}
  #       DAFT_NIGHTLY_UPLOAD_TOKEN: ${{ secrets.DAFT_NIGHTLY_UPLOAD_TOKEN }}
  #     run: |
  #       source ci/upload_wheels.sh
  #       set_upload_vars
  #       # trigger an upload to
  #       # https://anaconda.org/daft-nightly/getdaft
  #       # for cron jobs or "Run workflow" (restricted to main branch).
  #       # Tags will upload to
  #       # https://anaconda.org/daft/getdaft
  #       # The tokens were originally generated at anaconda.org
  #       upload_wheels

  # build_sdist_wheels:
  #   name: source wheel
  #   runs-on: ubuntu-latest
  #   strategy:
  #     fail-fast: false

  #   env:
  #     IS_PUSH: ${{ github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v') && ( ! endsWith(github.ref, 'dev0')) }}
  #     IS_SCHEDULE_DISPATCH: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}

  #   steps:
  #   - uses: actions/checkout@v3
  #     with:
  #       submodules: true
  #       fetch-depth: 0

  #   - uses: actions/setup-python@v4
  #     with:
  #       python-version: '3.11'


  #   - name: Patch local cargo toml
  #     run: python tools/patch_package_version.py


  #   - name: Build wheels
  #     run: poetry build -f sdist
  #   - uses: actions/upload-artifact@v3
  #     with:
  #       name: source_wheels
  #       path: ./dist/*
  #   - name: Publish sdist package to PYPI
  #     if: ${{ success() && (env.IS_PUSH == 'true') }}
  #     run: python -m twine upload --skip-existing --disable-progress-bar ./dist/*
  #     env:
  #       TWINE_USERNAME: __token__
  #       TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
  #     # Used to push the built sdist
  #   - uses: conda-incubator/setup-miniconda@v2
  #     with:
  #       auto-update-conda: true
  #       # Really doesn't matter what version we upload with
  #       # just the version we test with
  #       python-version: '3.8'
  #       channels: conda-forge
  #       channel-priority: true
  #       mamba-version: '*'

  #   - name: Install anaconda client
  #     shell: bash -el {0}
  #     run: conda install -q -y anaconda-client

  #   - name: Upload wheels to anaconda nightly
  #     if: ${{ success() && (env.IS_SCHEDULE_DISPATCH == 'true' || env.IS_PUSH == 'true') }}
  #     shell: bash -el {0}
  #     env:
  #       DAFT_STAGING_UPLOAD_TOKEN: ${{ secrets.DAFT_STAGING_UPLOAD_TOKEN }}
  #       DAFT_NIGHTLY_UPLOAD_TOKEN: ${{ secrets.DAFT_NIGHTLY_UPLOAD_TOKEN }}
  #     run: |
  #       source ci/upload_wheels.sh
  #       set_upload_vars
  #       # trigger an upload to
  #       # https://anaconda.org/daft-nightly/getdaft
  #       # for cron jobs or "Run workflow" (restricted to main branch).
  #       # Tags will upload to
  #       # https://anaconda.org/daft/getdaft
  #       # The tokens were originally generated at anaconda.org
  #       upload_wheels
