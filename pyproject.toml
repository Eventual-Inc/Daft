[build-system]
build-backend = "maturin"
requires = ["maturin>=1.5.0,<2.0.0"]

[project]
authors = [{name = "Eventual Inc", email = "daft@eventualcomputing.com"}]
dependencies = [
  "pyarrow >= 8.0.0",
  "fsspec",
  "tqdm",
  "typing-extensions >= 4.0.0"
]
description = "Distributed Dataframes for Multimodal Data"
dynamic = ["version"]
license = {file = "LICENSE"}
maintainers = [
  {name = "Sammy Sidhu", email = "sammy@eventualcomputing.com"},
  {name = "Jay Chia", email = "jay@eventualcomputing.com"}
]
name = "daft"
readme = "README.rst"
requires-python = ">=3.9"

[project.scripts]
daft = "daft.cli:main"

[project.urls]
homepage = "https://www.daft.ai"
repository = "https://github.com/Eventual-Inc/Daft"

[project.optional-dependencies]
all = ["daft[aws, azure, clickhouse, deltalake, gcp, hudi, huggingface, iceberg, lance, numpy, openai, pandas, ray, sentence-transformers, spark, sql, transformers, turbopuffer, unity]"]
aws = ["boto3"]
azure = []
clickhouse = ["clickhouse_connect"]
deltalake = ["deltalake", "packaging"]
gcp = []
hudi = ["pyarrow >= 8.0.0"]
huggingface = ["huggingface-hub"]
# TODO: pyiceberg 0.9.1 has a bug https://github.com/apache/iceberg-python/issues/1979. It was not
# triggered because we specify pyiceberg == 0.7.0 in requrements-dev.txt which hide this problem.
# See https://github.com/Eventual-Inc/Daft/issues/4868.
iceberg = ["pyiceberg >= 0.7.0, < 0.9.1", "packaging"]
lance = ["pylance"]
numpy = ["numpy"]
openai = ["openai"]
pandas = ["pandas"]
ray = [
  # Inherit existing Ray version. Get the "default" extra for the Ray dashboard.
  # TODO: we temporarily limit ray<2.48.0 because https://github.com/Eventual-Inc/Daft/issues/5027
  'ray[data, client]>=2.0.0, <2.48.0 ; platform_system != "Windows"',
  'ray[data, client]>=2.10.0, <2.48.0 ; platform_system == "Windows"',  # ray 2.10 has the pyarrow upper pin removed
  # Explicitly install packaging. See issue: https://github.com/ray-project/ray/issues/34806
  "packaging"
]
sentence-transformers = ["sentence-transformers"]
transformers = ["transformers", "torch", "torchvision"]
spark = ["googleapis-common-protos >= 1.56.4", "grpcio >= 1.48", "grpcio-status >= 1.48", "numpy >= 1.15", "pandas >= 1.0.5", "py4j >= 0.10.9.7", "pyspark == 3.5.5"]
sql = ["connectorx", "sqlalchemy", "sqlglot"]
turbopuffer = ["turbopuffer"]
unity = ["httpx <= 0.27.2", "unitycatalog"]
viz = []

[dependency-groups]
dev = [
  "ipdb",
  "maturin",
  "pre-commit",
  "docker",
  # Pinned aiohttp due to Ray connection issue in aiohttp==3.12.6
  "aiohttp==3.12.4",
  # Pinned httpx due to unitycatalog-python issue: https://github.com/unitycatalog/unitycatalog-python/issues/9
  "httpx==0.27.2",
  # Tracing
  "orjson==3.10.12",
  "py-spy>=0.3.14",
  "viztracer==0.15.6",
  # Testing frameworks
  "hypothesis==6.79.2",
  "pytest==7.4.3",
  "pytest-benchmark==4.0.0",
  "pytest-cov==4.1.0",
  "pytest-lazy-fixture==0.6.3",
  "memray==1.17.2; platform_system != \"Windows\"",
  "pytest-codspeed==2.2.1",
  # Testing dependencies
  "lxml==5.3.0",
  "dask[dataframe]==2024.4.1",
  "numpy==1.26.2",
  "pandas==2.1.3",
  "pandas-stubs==2.2.2.240807",
  "xxhash>=3.0.0",
  "Pillow==10.4.0",
  "opencv-python==4.10.0.84",
  "tiktoken==0.9.0",
  "duckdb==1.1.2",
  "datasets==4.0.0",
  # Pyarrow
  "pyarrow==20.0.0",
  "pyarrow-stubs==19.4",
  # Ray
  "ray[data, client]==2.34.0",
  # Lance
  "pylance>=0.20.0",
  # Iceberg
  "pyiceberg==0.7.0",
  "pydantic==2.10.6",
  "tenacity==8.2.3",
  # Delta Lake
  "deltalake==0.5.8; platform_system == \"Windows\"",
  "deltalake==1.0.2; platform_system != \"Windows\"",
  # Databricks
  "databricks-sdk==0.12.0",
  "unitycatalog==0.1.1",
  # SQL
  "sqlalchemy==2.0.36",
  "connectorx==0.2.3; platform_system == \"Linux\" and platform_machine == \"aarch64\"",
  "connectorx==0.3.3; platform_system != \"Linux\" or platform_machine != \"aarch64\"",
  "trino[sqlalchemy]==0.328.0",
  "PyMySQL==1.1.0",
  "psycopg2-binary==2.9.10",
  "sqlglot==23.3.0",
  "pyodbc==5.1.0",
  # AWS
  "s3fs==2023.12.0",
  "boto3==1.36.20",
  "boto3-stubs[essential,glue,s3,s3tables]==1.38.46",
  "moto[glue,s3,s3tables,server]==5.1.1",
  # Azure
  "adlfs==2024.7.0",
  "azure-storage-blob==12.24.0",
  # GCS
  "gcsfs==2023.12.0",
  # Hugging Face
  "huggingface-hub==0.34.4",
  # Daft connect testing
  "pyspark==3.5.5",
  "grpcio==1.68.1",
  "grpcio-status==1.67.0",
  # AI
  "vllm; platform_system == \"Linux\" and platform_machine == \"x86_64\"",
  "openai==1.100",
  # Clickhouse
  "clickhouse-connect",
  # mcap
  "mcap==1.3.0",
  "mcap-ros2-support==0.5.5",
  "mcap-protobuf-support==0.5.3"
]
docs = [
  "markdown-exec",
  "mkdocs-jupyter",
  "mkdocs-material",
  "mkdocs-macros-plugin",
  "mkdocs-simple-hooks",
  "pymdown-extensions",
  "mkdocs-material[imaging]",
  "mkdocstrings-python",
  "mkdocs-minify-plugin",
  "mkdocs-redirects",
  "mkdocs-gen-files",
  "griffe",
  "mkdocs-literate-nav",
  "Jinja2"
]
lint = [
  "ruff",
  "black",
  "isort",
  "mypy"
]

[tool]

[tool.codespell]
check-filenames = true
check-hidden = true
ignore-words-list = "crate,arithmetics,ser,acter,MOR"
# Feel free to un-skip examples, and experimental, you will just need to
# work through many typos (--write-changes and --interactive will help)
skip = "tests/series/*,target,.git,.venv,venv,data,*.csv,*.csv.*,*.html,*.json,*.jsonl,*.pdf,*.txt,*.ipynb,*.tiktoken,*.sql,tests/table/utf8/*,tests/table/binary/*,*.warc,tests/ai/*"

[tool.maturin]
# "python" tells pyo3 we want to build an extension module (skips linking against libpython.so)
features = ["python"]

[tool.mypy]
exclude = ['daft/pickle/*.py$']
files = ["daft/**/*.py", "daft/**/*.pyx", "tests/**/*.py"]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true

[[tool.mypy.overrides]]
ignore_missing_imports = true
module = [
  "pyarrow.*",
  "fsspec.*",
  "icebridge.*",
  "cloudpickle.*",
  "docker.*",
  "uvicorn.*",
  "numba.*",
  "viztracer.*"
]

[[tool.mypy.overrides]]
enable_error_code = ["attr-defined"]
module = 'daft.*'
warn_return_any = false

[tool.pyright]
typeCheckingMode = "off"
venv = ".venv"
venvPath = "."

[[tool.pyright.executionEnvironments]]
root = ".github/ci-scripts"

[[tool.pyright.executionEnvironments]]
root = "tools"

[[tool.pyright.executionEnvironments]]
root = "daft_dashboard"

[tool.pytest.ini_options]
addopts = "-m 'not (integration or benchmark or hypothesis)'"
minversion = "6.0"
testpaths = [
  "tests"
]

[tool.uv.sources.daft_dashboard]
workspace = true

[tool.uv.workspace]
members = ["daft_dashboard"]
