from __future__ import annotations

import pytest

from daft.expressions import col
from daft.table import MicroPartition


@pytest.mark.parametrize(
    "input_data,expected_lengths",
    [
        # Basic ASCII strings
        (
            ["Hello", "World!", "", "Test"],
            [5, 6, 0, 4],
        ),
        # Special UTF-8 sequences
        (
            [
                "â˜ƒ",  # UTF-8 encoded snowman
                "ðŸ˜‰",  # UTF-8 encoded winking face
                "ðŸŒˆ",  # UTF-8 encoded rainbow
                "Helloâ˜ƒWorld",  # Mixed ASCII and UTF-8
                "â˜ƒðŸ˜‰ðŸŒˆ",  # Multiple UTF-8 characters
                "Hello\u0000World",  # String with null character
            ],
            [1, 1, 1, 11, 3, 11],
        ),
        # Nulls and empty strings
        (
            ["Hello", None, "", "\u0000", None, "Test", ""],
            [5, None, 0, 1, None, 4, 0],
        ),
        # Very large strings
        (
            ["x" * 1000, "y" * 10000, "z" * 100000],
            [1000, 10000, 100000],
        ),
        # Mixed strings with different sizes
        (
            [
                "a",  # Single character
                "ab",  # Two characters
                "abc",  # Three characters
                "â˜ƒ",  # Single UTF-8 character
                "â˜ƒâ˜ƒ",  # Two UTF-8 characters
                "â˜ƒâ˜ƒâ˜ƒ",  # Three UTF-8 characters
            ],
            [1, 2, 3, 1, 2, 3],
        ),
        # Strings with repeated patterns
        (
            [
                "\u0000" * 5,  # Repeated null characters
                "ab" * 5,  # Repeated ASCII pattern
                "â˜ƒ" * 5,  # Repeated UTF-8 snowman
                "ðŸ˜‰" * 5,  # Repeated UTF-8 winking face
            ],
            [5, 10, 5, 5],
        ),
        # Edge cases with single characters
        (
            [
                "\u0000",  # Null character
                "\u0001",  # Start of heading
                "\u001f",  # Unit separator
                " ",  # Space
                "\u007f",  # Delete
                "â˜ƒ",  # Snowman
                "ðŸ˜‰",  # Winking face
            ],
            [1, 1, 1, 1, 1, 1, 1],
        ),
        # Complex UTF-8 sequences
        (
            [
                "â˜ƒ",  # Snowman
                "ðŸ˜‰",  # Winking face
                "â˜ƒðŸ˜‰",  # Snowman + Winking face
                "ðŸŒˆ",  # Rainbow
                "ðŸŒˆâ˜ƒ",  # Rainbow + Snowman
                "â˜ƒðŸŒˆðŸ˜‰",  # Snowman + Rainbow + Winking face
            ],
            [1, 1, 2, 1, 2, 3],
        ),
        # Mixed content lengths
        (
            [
                "Helloâ˜ƒWorld",  # ASCII + UTF-8 + ASCII
                "\u0000Hello\u0000World\u0000",  # Null-separated
                "â˜ƒHelloâ˜ƒWorldâ˜ƒ",  # UTF-8-separated
                "HelloðŸ˜‰World",  # ASCII + UTF-8 + ASCII
            ],
            [11, 13, 13, 11],
        ),
    ],
)
def test_utf8_length(input_data: list[str | None], expected_lengths: list[int | None]) -> None:
    table = MicroPartition.from_pydict({"col": input_data})
    result = table.eval_expression_list([col("col").str.length()])
    assert result.to_pydict() == {"col": expected_lengths}


def test_utf8_length_large_sequences() -> None:
    # Test with very large string sequences
    large_data = [
        "x" * 1_000_000,  # 1MB of 'x'
        "\u0000" * 1_000_000,  # 1MB of null characters
        "Hello\u0000World" * 100_000,  # Repeated pattern with null
        "â˜ƒ" * 333_333,  # Many snowmen
        None,  # Null value
        "",  # Empty string
    ]
    expected_lengths = [
        1_000_000,
        1_000_000,
        1_100_000,  # 11 chars * 100_000
        333_333,  # 1 char * 333_333
        None,
        0,
    ]

    table = MicroPartition.from_pydict({"col": large_data})
    result = table.eval_expression_list([col("col").str.length()])
    assert result.to_pydict() == {"col": expected_lengths}
