# Quickstart

<!--
todo(docs - jay): Incorporate SQL examples

todo(docs): Add link to notebook to DIY (notebook is in mkdocs dir, but idk how to host on colab)

todo(docs): What does the actual output look like for some of these examples? should we update it visually?
-->

Daft is the best multimodal data processing engine that allows you to load data from anywhere, transform it with a powerful DataFrame API and AI functions, and store it in your destination of choice. In this quickstart, you'll see what this looks like in practice with a realistic e-commerce data workflow.

### Install Daft

You can install Daft using `pip`. Run the following command in your terminal or notebook:

=== "ğŸ Python"

    ```python
    pip install daft
    ```

<!-- For more advanced installation options, please see [Installation](install.md). -->

### Load Your Data

Let's start by loading an e-commerce dataset from Hugging Face. [This dataset](https://huggingface.co/datasets/calmgoose/amazon-product-data-2020) contains 10,000 Amazon products from diverse categories including electronics, toys, home goods, and more. Each product includes details like names, prices, descriptions, technical specifications, and product images.

=== "ğŸ Python"

    ```python
    import daft

    df = daft.read_huggingface("calmgoose/amazon-product-data-2020")
    ```

!!! note "Load from anywhere"

    Daft can load data from many sources including [S3](connectors/aws.md), [Iceberg](connectors/iceberg.md), [Delta Lake](connectors/delta_lake.md), [Hudi](connectors/hudi.md), and [more](connectors/index.md). We're using Hugging Face here as a demonstration.

### Inspect Your Data

Now let's take a look at what we loaded. You can inspect the DataFrame by simply printing it:

=== "ğŸ Python"

    ```python
    df
    ```

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Uniq Id â”† Product Name â”† Category â”†      â€¦     â”† Variants â”† Product Url â”† Is Amazon Seller â”‚
â”‚ ---     â”† ---          â”† ---      â”†            â”† ---      â”† ---         â”† ---              â”‚
â”‚ String  â”† String       â”† String   â”† (9 hidden) â”† String   â”† String      â”† String           â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

(No data to display: Dataframe not materialized)
```

You see the above output because **Daft is lazy by default** - it displays the schema (column names and types) but doesn't actually load or process your data until you explicitly tell it to. This allows Daft to optimize your entire workflow before executing anything.

To actually view your data, you have two options:

**Option 1: Preview with `.show()`** - View the first few rows:

=== "ğŸ Python"

    ```python
    df.show(2)
    ```

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Uniq Id          â”† Product Name     â”† Category         â”†      â€¦     â”† Variants         â”† Product Url     â”† Is Amazon â”‚
â”‚ ---              â”† ---              â”† ---              â”†            â”† ---              â”† ---             â”† Seller    â”‚
â”‚ String           â”† String           â”† String           â”† (9 hidden) â”† String           â”† String          â”† ---       â”‚
â”‚                  â”†                  â”†                  â”†            â”†                  â”†                 â”† String    â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 4c69b61db1fc16e7 â”† DB Longboards    â”† Sports &         â”† â€¦          â”† https://www.amaz â”† https://www.ama â”† Y         â”‚
â”‚ 013b43fc926e5â€¦   â”† CoreFlex Crossbâ€¦ â”† Outdoors |       â”†            â”† on.com/DB-Lonâ€¦   â”† zon.com/DB-Lonâ€¦ â”†           â”‚
â”‚                  â”†                  â”† Outdoor Râ€¦       â”†            â”†                  â”†                 â”†           â”‚
â”œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¼â•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ•Œâ”¤
â”‚ 66d49bbed043f5be â”† Electronic Snap  â”† Toys & Games |   â”† â€¦          â”† None             â”† https://www.ama â”† Y         â”‚
â”‚ 260fa9f7fbff5â€¦   â”† Circuits Miniâ€¦   â”† Learning & Eduâ€¦  â”†            â”†                  â”† zon.com/Electrâ€¦ â”†           â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

(Showing first 2 rows)
```

This materializes and displays just the first 2 rows, which is perfect for quickly inspecting your data without loading the entire dataset.

**Option 2: Materialize with `.collect()`** - Load the entire dataset:

=== "ğŸ Python"

    ```python
    # df.collect()
    ```

This would materialize the entire DataFrame (all 10,000 rows in this case) into memory. Use `.collect()` when you need to work with the full dataset in memory.

### Working with a Smaller Dataset

For quick experimentation, let's create a smaller, simplified version of the dataframe with just the essential columns:

=== "ğŸ Python"

    ```python
    # Select only the columns we need and limit to 5 rows for faster iteration
    df = df.select("Product Name", "About Product", "Image").limit(5)
    ```

Now we have a manageable dataset of 5 products with just the product name, description, and image URLs. This simplified dataset lets us explore Daft's features without the overhead of unnecessary columns.

### Downloading Images

Let's extract and download product images. The `Image` column contains pipe-separated URLs. We'll extract the first URL and download it:

=== "ğŸ Python"

    ```python
    # Extract the first image URL from the pipe-separated list
    # The pattern captures everything before the first pipe or the entire string if no pipe
    df = df.with_column(
        "first_image_url",
        daft.functions.regexp_extract(
            df["Image"],
            r"^([^|]+)",  # Extract everything before the first pipe
            1  # Get the first capture group
        )
    )

    # Download the image data
    df = df.with_column(
        "image_data",
        df["first_image_url"].url.download(on_error="null")
    )

    # Check what we have
    df.select("Product Name", "first_image_url").show(3)
    ```

This demonstrates Daft's multimodal capabilities:
- **Pattern extraction**: Use `regexp_extract()` to parse structured text
- **URL handling**: Download content directly with `.url.download()`
- **Error handling**: Use `on_error="null"` to gracefully handle failed downloads

The downloaded image data is now ready for further processing, such as running image classification models, extracting embeddings, or performing transformations.

### What's Next?

Now that you have a basic sense of Daft's functionality and features, here are some more resources to help you get the most out of Daft:

!!! tip "Try this on Kubernetes"

    Want to run this example on Kubernetes? Check out our [Kubernetes quickstart](distributed/kubernetes.md).

**Work with your favorite table and catalog formats**:

<div class="grid cards" markdown>

- [**Apache Hudi**](connectors/hudi.md)
- [**Apache Iceberg**](connectors/iceberg.md)
- [**AWS Glue**](connectors/glue.md)
- [**AWS S3Tables**](connectors/s3tables.md)
- [**Delta Lake**](connectors/delta_lake.md)
- [**Hugging Face Datasets**](connectors/huggingface.md)
- [**Unity Catalog**](connectors/unity_catalog.md)
<!-- - [**LanceDB**](io/lancedb.md) -->

</div>

<!-- **Coming from?**

<div class="grid cards" markdown>

- [:simple-dask: **Dask Migration Guide**](migration/dask_migration.md)

</div> -->

**Explore our [Examples](examples/index.md) to see Daft in action:**

<div class="grid cards" markdown>

- [:material-image-edit: **MNIST Digit Classification**](examples/mnist.md)
- [:octicons-search-16: **Running LLMs on the Red Pajamas Dataset**](examples/llms-red-pajamas.md)
- [:material-image-search: **Querying Images with UDFs**](examples/querying-images.md)
- [:material-image-sync: **Image Generation on GPUs**](examples/image-generation.md)
- [:material-window-closed-variant: **Window Functions in Daft**](examples/window-functions.md)

</div>
