{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78db424a-96b5-46f3-bd32-484f5c6b92a3",
   "metadata": {
    "id": "78db424a-96b5-46f3-bd32-484f5c6b92a3"
   },
   "source": [
    "# Generating Images from Text with DALL-E\n",
    "\n",
    "In this tutorial, we will be using the DALL-E model to generate images from text. We will explore how to use GPUs with Daft to accelerate computations.\n",
    "\n",
    "To run this tutorial:\n",
    "\n",
    "1. You will need access to a GPU. If you are on Google Colab, you may switch to a GPU runtime by going to the menu `Runtime -> Change runtime type -> Hardware accelerator -> GPU -> Save`.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019805d9-4e9f-4306-8f18-a565cb1e8845",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "019805d9-4e9f-4306-8f18-a565cb1e8845",
    "outputId": "f48e4a66-21cd-4b93-e8cb-261ae8c8aec8"
   },
   "outputs": [],
   "source": [
    "!pip install getdaft --pre --extra-index-url https://pypi.anaconda.org/daft-nightly/simple\n",
    "!pip install min-dalle torch Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da65a96-e4fe-4795-92d0-a5e631b58e33",
   "metadata": {
    "id": "4da65a96-e4fe-4795-92d0-a5e631b58e33"
   },
   "source": [
    "## Setting Up\n",
    "\n",
    "First, let's download a Parquet file containing some example data from the laion_improved_aesthetics 6.5 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f574451-9a5f-4795-8aa2-58ce0892411a",
   "metadata": {
    "id": "0f574451-9a5f-4795-8aa2-58ce0892411a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "PARQUET_URL = \"https://huggingface.co/datasets/ChristophSchuhmann/improved_aesthetics_6.5plus/resolve/main/data/train-00000-of-00001-6f24a7497df494ae.parquet\"\n",
    "PARQUET_PATH = \"laion_improved_aesthetics_6_5.parquet\"\n",
    "\n",
    "if not os.path.exists(PARQUET_PATH):\n",
    "    with open(PARQUET_PATH, \"wb\") as f:\n",
    "        response = urllib.request.urlopen(PARQUET_URL)\n",
    "        f.write(response.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c4950-ca59-4aa9-ad82-6cfaa516850a",
   "metadata": {
    "id": "7d8c4950-ca59-4aa9-ad82-6cfaa516850a"
   },
   "source": [
    "Now we can load this Parquet file into Daft and peek at the data like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806451f8-68af-462a-af7b-ff5480425a3a",
   "metadata": {
    "id": "806451f8-68af-462a-af7b-ff5480425a3a"
   },
   "outputs": [],
   "source": [
    "from daft import DataFrame, col, udf\n",
    "\n",
    "parquet_df = DataFrame.read_parquet(PARQUET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3b619-beaf-465e-83f2-5ab71638dcc1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "e1e3b619-beaf-465e-83f2-5ab71638dcc1",
    "outputId": "e52133d2-5694-49a0-e385-758cf5b1b203"
   },
   "outputs": [],
   "source": [
    "parquet_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257cd91-db90-4803-afd9-9fdf571cf755",
   "metadata": {
    "id": "b257cd91-db90-4803-afd9-9fdf571cf755"
   },
   "outputs": [],
   "source": [
    "parquet_df = parquet_df.select(col(\"URL\"), col(\"TEXT\"), col(\"AESTHETIC_SCORE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28047df-bf05-47df-b4d4-3507a8f7d2ac",
   "metadata": {
    "id": "f28047df-bf05-47df-b4d4-3507a8f7d2ac"
   },
   "source": [
    "## Downloading Images\n",
    "\n",
    "Like many datasets, instead of storing the actual images in the dataset's files it looks like the Dataset authors have instead opted to store a URL to the image.\n",
    "\n",
    "Let's use Daft's builtin functionality to download the images and open them as PIL Images - all in just a few lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5cd84-4526-4a91-9fd5-f4e78f35965d",
   "metadata": {
    "id": "f1e5cd84-4526-4a91-9fd5-f4e78f35965d"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "parquet_df_with_long_strings = parquet_df.where(col(\"TEXT\").str.length() > 50)\n",
    "images_df = parquet_df_with_long_strings.with_column(\n",
    "    \"image\",\n",
    "    # Download the images, then load them as PIL.Images if the download was successful\n",
    "    col(\"URL\").url.download().apply(lambda data: PIL.Image.open(io.BytesIO(data)) if data is not None else None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1361728-8b1a-4e6e-9632-ddd17cad948b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "c1361728-8b1a-4e6e-9632-ddd17cad948b",
    "outputId": "1c2ce3a4-63a1-4f77-ce2e-e3ecea2a3e1f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "images_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gCTmONUl81Vw",
   "metadata": {
    "id": "gCTmONUl81Vw"
   },
   "source": [
    "# Downloading the Model\n",
    "\n",
    "Let's download the model's weights - the `min-dalle` library that we are using here allows us to cache the downloaded model weights on disk by calling some `.download_*` methods. Since this tutorial is ran entirely on the local machine, this will speed up all subsequent steps by reusing the downloaded model weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y71-_0BIjrVm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y71-_0BIjrVm",
    "outputId": "8d2febb6-e892-4e84-d905-92b86ca3a599"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "from min_dalle import MinDalle\n",
    "\n",
    "model = MinDalle(\n",
    "    models_root='./pretrained',\n",
    "    dtype=torch.float32,\n",
    "    device=\"cpu\",\n",
    "    is_mega=False, \n",
    "    is_reusable=False,\n",
    ")\n",
    "model.download_encoder()\n",
    "model.download_decoder()\n",
    "model.download_detokenizer()\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa31d0-bcaa-44c6-8a5b-8b1b6ff51f93",
   "metadata": {
    "id": "a7fa31d0-bcaa-44c6-8a5b-8b1b6ff51f93"
   },
   "source": [
    "## Running a model (without a GPU)\n",
    "\n",
    "Let's run the model on our data without a GPU. Note that the next cell will take a while to run - almost 2 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd603b-86c1-4b77-94ea-6025cd298da8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "affd603b-86c1-4b77-94ea-6025cd298da8",
    "outputId": "e3ce9a76-64b1-4bfc-ca12-104dff3dbe71"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from min_dalle import MinDalle\n",
    "\n",
    "\n",
    "@udf(return_type=PIL.Image.Image)\n",
    "class GenerateImageFromText:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = MinDalle(\n",
    "            models_root='./pretrained',\n",
    "            dtype=torch.float32,\n",
    "            device=\"cpu\",\n",
    "            is_mega=False, \n",
    "            is_reusable=True\n",
    "        )\n",
    "\n",
    "    def __call__(self, text_col):\n",
    "        return [\n",
    "            self.model.generate_image(\n",
    "                t,\n",
    "                seed=-1,\n",
    "                grid_size=1,\n",
    "                is_seamless=False,\n",
    "                temperature=1,\n",
    "                top_k=256,\n",
    "                supercondition_factor=32,\n",
    "            ) for t in text_col\n",
    "        ]\n",
    "\n",
    "# Uncomment the following line to run the cell which will take about 2 minutes.\n",
    "# %time images_df.with_column(\"generated_image\", GenerateImageFromText(col(\"TEXT\"))).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad627801-b3f7-46fb-8415-579c9118cb78",
   "metadata": {
    "id": "ad627801-b3f7-46fb-8415-579c9118cb78"
   },
   "source": [
    "That took a long time since our model was running only on the CPU. If you are on the default Google Colab runtime, this would have taken almost 2 minutes! Running it on more images and more steps would take too long.\n",
    "\n",
    "Let's see how we can tell Daft that this UDF requires a GPU, and load the model to run on a GPU instead. Note that **the following cell will throw an error if you are not running on a machine with a GPU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86781713-b2cc-469a-8764-864d20362418",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "86781713-b2cc-469a-8764-864d20362418",
    "outputId": "8f5a05d5-e57d-4b9d-961d-3d618e09cad3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from min_dalle import MinDalle\n",
    "\n",
    "# Tell Daft to use N number of GPUs with num_gpus=N\n",
    "@udf(return_type=PIL.Image.Image, num_gpus=1)\n",
    "class GenerateImageFromTextGPU:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = MinDalle(\n",
    "            models_root='./pretrained',\n",
    "            dtype=torch.float32,\n",
    "            # Tell the min-dalle library to load model on GPU\n",
    "            device=\"cuda\",\n",
    "            is_mega=False, \n",
    "            is_reusable=True\n",
    "        )\n",
    "\n",
    "    def __call__(self, text_col):\n",
    "        return [\n",
    "            self.model.generate_image(\n",
    "                t,\n",
    "                seed=-1,\n",
    "                grid_size=1,\n",
    "                is_seamless=False,\n",
    "                temperature=1,\n",
    "                top_k=256,\n",
    "                supercondition_factor=32,\n",
    "            ) for t in text_col\n",
    "        ]\n",
    "\n",
    "%time images_df.with_column(\"generated_image\", GenerateImageFromTextGPU(col(\"TEXT\"))).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b390c",
   "metadata": {
    "id": "398b390c"
   },
   "source": [
    "Much better! On Google Colab, this runs in just under 15 seconds which gives us a speedup of about 8x just by running the model on a GPU instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vCCQboOkpaSo",
   "metadata": {
    "id": "vCCQboOkpaSo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
