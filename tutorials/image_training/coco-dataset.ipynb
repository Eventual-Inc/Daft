{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14b6cd6-ae2c-42cd-b7a8-b5ad197da52c",
   "metadata": {},
   "source": [
    "# Training on the COCO Dataset made simple with Daft\n",
    "\n",
    "What is the COCO Dataset?\n",
    "\n",
    "Image dataset with labels and annotations:\n",
    "\n",
    "![coco-example.png](https://cocodataset.org/images/coco-examples.jpg)\n",
    "\n",
    "With Daft, we can run data querying/processing really easily for:\n",
    "\n",
    "1. Model Training\n",
    "2. Model Evaluation\n",
    "3. Dataset curation\n",
    "4. Data exploration/understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7509d28-3463-4984-8d15-548f0b0cca0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from daft import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3c8b2-58b2-459b-a6a9-8d1aaae8e38d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !aws sso login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f5d93-59d1-43c4-9a84-34009ce2fb6e",
   "metadata": {},
   "source": [
    "## Connecting Daft to Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fddf6ab-b35a-474e-a02f-94757b4cb748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import daft\n",
    "\n",
    "USE_REMOTE_CLUSTER = False\n",
    "RAY_ADDRESS = \"ray://localhost:10001\" if USE_REMOTE_CLUSTER else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ceefd0-8ea1-4a65-88c2-86888d16648e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "# Set up connection to Ray cluster if USE_REMOTE_CLUSTER=True\n",
    "if USE_REMOTE_CLUSTER:\n",
    "    ray.init(\n",
    "        address=RAY_ADDRESS,\n",
    "        runtime_env={\n",
    "            \"pip\": [\n",
    "                \"getdaft\",\n",
    "                \"pillow\",\n",
    "                \"s3fs\",\n",
    "                \"torch\",\n",
    "                \"torchvision\",\n",
    "                \"IPython\",\n",
    "            ]\n",
    "        },\n",
    "    )\n",
    "    print(ray.available_resources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e827f58-0183-443f-b9ce-c4824441d635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daft.context.set_runner_ray(address=RAY_ADDRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf82db1-af52-4953-bbc2-b8383e8aba53",
   "metadata": {},
   "source": [
    "## Read some data (stored as Parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae6990-40c2-44a1-8765-f56113a51966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_df = DataFrame.read_parquet(\"s3://daft-public-data/coco-2017-parquet/images.parquet\")\n",
    "annotations_df = DataFrame.read_parquet(\"s3://daft-public-data/coco-2017-parquet/annotations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59063bd6-8f64-4177-a102-1f9e79c6507f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f22d3-92b1-4b12-bd7e-0e510d16b722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6b75e-4d66-41c5-ab81-10781655e24f",
   "metadata": {},
   "source": [
    "# Data Querying\n",
    "\n",
    "Let's take a look at the rough distribution of data with a count of the number of rows, grouped by the \"category ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31da9d3-ef24-4165-9588-3766b03d179e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_df \\\n",
    "    .groupby(\"category_id\") \\\n",
    "    .agg([(annotations_df[\"category_id\"].alias(\"count\"), \"count\")]) \\\n",
    "    .sort(\"count\", desc=True) \\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca040b-89ab-4a18-b805-9642f03b3060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_df = annotations_df.where(annotations_df[\"category_id\"] < 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe787f4-aeee-46d8-99aa-84293cd36b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_df = annotations_df.select(\"category_id\", \"bbox\", \"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3987d26-7c5a-449b-b9b6-52afa16e047a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77572c24-861e-4805-bc12-f8a44eda1e6d",
   "metadata": {},
   "source": [
    "# Under the hood\n",
    "\n",
    "How does this run on Ray? Let's take a look at Daft's \"logical plan\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc904ed-9ef8-4c5c-b0b5-d9ecc5c45e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4353bb9-7b84-48de-a1e4-e5a9fdb8553c",
   "metadata": {},
   "source": [
    "Daft translates this Logical Plan into a series of Ray function calls to execute the plan, from reading files to running functions and models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d7557-3f58-4c17-853a-2053a2089f2c",
   "metadata": {},
   "source": [
    "## Join Annotations with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dfac88-dbd0-4d99-b5bc-1c1ad97a2151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_df = annotations_df.join(\n",
    "    images_df,\n",
    "    left_on=\"image_id\",\n",
    "    right_on=\"id\",\n",
    ")\n",
    "joined_df = joined_df.select(\n",
    "    joined_df[\"id\"],\n",
    "    joined_df[\"coco_url\"],\n",
    "    joined_df[\"bbox\"],\n",
    "    joined_df[\"category_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8b818-a3d1-47d4-84c1-e1d26ee11022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d73fb-d24e-4fb7-baea-1ff3517b3b3a",
   "metadata": {},
   "source": [
    "## Repartitioning\n",
    "\n",
    "We split our dataframe into \"64 partitions\", which means that Daft can operate on each partition in parallel using Ray as its resource scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450eda16-6bf9-4d40-8c97-d4c8aecc4afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Before: `joined_df` has {joined_df.num_partitions()} partitions.\")\n",
    "\n",
    "joined_df = joined_df.into_partitions(64).collect()\n",
    "\n",
    "print(f\"After: `joined_df` has {joined_df.num_partitions()} partitions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e24d1-2b5f-4cec-ae5c-589c4fff2e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not USE_REMOTE_CLUSTER:\n",
    "    joined_df = joined_df.limit(128)\n",
    "\n",
    "print(f\"Dataframe has: {joined_df.count_rows()} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2d5ee-038f-4cd1-8fff-e12c42290ca8",
   "metadata": {},
   "source": [
    "# Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f3990-5ea4-4840-987e-e93c7ec53066",
   "metadata": {},
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebb1b4-f895-450e-aecb-7bae312decf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_df = joined_df.with_column(\n",
    "    \"image_bytes\",\n",
    "    joined_df[\"coco_url\"].url.download(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446247b-5133-4f19-af8b-b38de82ee49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc55d298-d165-4a79-abc2-d090a331758e",
   "metadata": {},
   "source": [
    "## Load images from bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68e3e2-a1a4-4a68-8686-e46b7f46292d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "def bytes_to_pil(b: bytes) -> PIL.Image.Image:\n",
    "    return PIL.Image.open(io.BytesIO(b)) if b is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930c8ed-95e9-4294-b9d0-ca34548d3ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_df = joined_df.with_column(\n",
    "    \"pil_image\",\n",
    "    joined_df[\"image_bytes\"].apply(bytes_to_pil),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a477e-d69e-4a2f-9ebc-2232d2e8c107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a5ef0-ec43-44ce-859e-f8e1b4958d92",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07fffef-8d81-498d-8018-97443a0c9d7c",
   "metadata": {},
   "source": [
    "## Crop images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7593d-62f1-41ae-a5b9-c59ca7a25971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from daft import udf\n",
    "from daft.types import ExpressionType\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@udf(\n",
    "    return_dtype=ExpressionType.python(PIL.Image.Image),\n",
    "    input_columns={\"images\": list, \"bboxes\": list},\n",
    ")\n",
    "def crop_images(images, bboxes):\n",
    "    return [img.crop((x, y, x+w, y+h)).resize((32, 32)) for img, [x, y, w, h] in zip(images, bboxes)]\n",
    "\n",
    "\n",
    "joined_df = joined_df.with_column(\n",
    "    \"cropped_img\",\n",
    "    crop_images(joined_df[\"pil_image\"], joined_df[\"bbox\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268dfe0-8b1e-4f80-9890-f274dbf2a2fe",
   "metadata": {},
   "source": [
    "## Convert image to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e70bd-ddc4-4646-a8d7-01fce7bd8f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def img_to_numpy(img) -> np.ndarray:\n",
    "    arr = np.array(img).reshape((32, 32, -1))\n",
    "    if arr.shape == (32, 32, 1):\n",
    "        arr = arr.repeat(3, axis=2)\n",
    "    return arr\n",
    "\n",
    "joined_df = joined_df.with_column(\n",
    "    \"np_arr\",\n",
    "    joined_df[\"cropped_img\"].apply(img_to_numpy),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b94d35-b3a1-45ad-93b9-f9f7dcb563be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f6396-1013-49cb-b2bb-1f93c447ccb7",
   "metadata": {},
   "source": [
    "# Daft DataFrame ➔ Ray Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1ec9c-cb51-4cc8-9fea-5be8b9ee62d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = joined_df.select(\n",
    "    joined_df[\"np_arr\"].alias(\"image\"),\n",
    "    joined_df[\"category_id\"].alias(\"label\"),\n",
    ").to_ray_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea54afc-fdc4-49f6-a1ae-3bb024cc2a6c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Now... It's just Ray!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b25d31a-44ef-4e66-b2ff-82fb8976af22",
   "metadata": {
    "tags": []
   },
   "source": [
    "Training code adapted from Ray AIR's image classification tutorial: https://docs.ray.io/en/latest/ray-air/examples/torch_image_example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd56b03-8ade-4a01-ab12-8e7a69920806",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "###\n",
    "# Neural Network definition\n",
    "###\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "###\n",
    "# Train Loop\n",
    "###\n",
    "    \n",
    "from ray import train\n",
    "from ray.air import session, Checkpoint\n",
    "from ray.train.torch import TorchCheckpoint\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    model = train.torch.prepare_model(Net())\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    train_dataset_shard = session.get_dataset_shard(\"train\")\n",
    "\n",
    "    for epoch in range(2):\n",
    "        running_loss = 0.0\n",
    "        train_dataset_batches = train_dataset_shard.iter_torch_batches(\n",
    "            batch_size=config[\"batch_size\"], device=train.torch.get_device()\n",
    "        )\n",
    "        for i, batch in enumerate(train_dataset_batches):\n",
    "            # get the inputs and labels\n",
    "            inputs, labels = batch[\"image\"], batch[\"label\"]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        metrics = dict(running_loss=running_loss)\n",
    "        checkpoint = TorchCheckpoint.from_state_dict(model.state_dict())\n",
    "        session.report(metrics, checkpoint=checkpoint)\n",
    "\n",
    "###\n",
    "# Preprocessing pipeline\n",
    "###\n",
    "        \n",
    "from ray.data.preprocessors import TorchVisionPreprocessor\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "preprocessor = TorchVisionPreprocessor(columns=[\"image\"], transform=transform)\n",
    "\n",
    "###\n",
    "# Trainer definition\n",
    "###\n",
    "\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.air.config import ScalingConfig, RunConfig\n",
    "from ray.tune.syncer import SyncConfig\n",
    "\n",
    "use_gpu = ray.available_resources().get(\"GPU\", 0) >= 2\n",
    "\n",
    "run_config = None\n",
    "if USE_REMOTE_CLUSTER:\n",
    "    run_config = RunConfig(sync_config=SyncConfig(upload_dir=\"s3://eventual-dev-scratch/ray-meetup-demo/\"))\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\"batch_size\": 8 if not USE_REMOTE_CLUSTER else 32},\n",
    "    datasets={\"train\": train_dataset},\n",
    "    scaling_config=ScalingConfig(num_workers=2 if not USE_REMOTE_CLUSTER else 16, use_gpu=use_gpu),\n",
    "    preprocessor=preprocessor,\n",
    "    run_config=run_config,\n",
    ")\n",
    "result = trainer.fit()\n",
    "latest_checkpoint = result.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00821a73-d0ce-45f5-9086-c7bf0fb9bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9066df-61aa-461d-9955-48df2389ecf7",
   "metadata": {},
   "source": [
    "**Now, use the model weights in `latest_checkpoint` to evaluate the train dataset!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426a95a-7301-4d45-b3cb-8b86e09afce5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchPredictor\n",
    "from ray.train.batch_predictor import BatchPredictor\n",
    "\n",
    "if not USE_REMOTE_CLUSTER:\n",
    "    batch_predictor = BatchPredictor.from_checkpoint(\n",
    "        checkpoint=latest_checkpoint,\n",
    "        predictor_cls=TorchPredictor,\n",
    "        model=Net(),\n",
    "    )\n",
    "    model_eval_results_ds: ray.data.Dataset = batch_predictor.predict(\n",
    "        data=train_dataset,\n",
    "        dtype=torch.float,\n",
    "        feature_columns=[\"image\"],\n",
    "        keep_columns=[\"label\"],\n",
    "        # We will use GPU if available.\n",
    "        num_gpus_per_worker=ray.available_resources().get(\"GPU\", 0)\n",
    "    )\n",
    "\n",
    "# Checkpoints seem to be broken for remote execution, we write our own custom code to perform inference\n",
    "else:\n",
    "    import pyarrow as pa\n",
    "    import pandas as pd\n",
    "    from ray.data.extensions.tensor_extension import ArrowTensorArray\n",
    "\n",
    "    uri = latest_checkpoint.uri\n",
    "    def predict(batch: pd.DataFrame) -> pa.Table:\n",
    "        checkpoint = Checkpoint.from_uri(uri)\n",
    "        model = checkpoint.get_model(Net())\n",
    "        return pa.Table.from_pydict({\n",
    "            \"predictions\": ArrowTensorArray.from_numpy([one_hot.detach().numpy() for one_hot in model(torch.Tensor(np.array(list(batch[\"image\"]))).permute(0, 3, 1, 2))]),\n",
    "            \"label\": batch[\"label\"],\n",
    "        })\n",
    "\n",
    "    model_eval_results_ds = train_dataset.map_batches(predict, batch_format=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8e89d-89fe-46d9-8f22-b8e73235e1d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_eval_results_ds.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801156fc-3c18-4af3-a9ae-c2267e4377f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Ray Datasets ➔ Daft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d93ab-6510-4512-b5ce-283667322ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_df = DataFrame.from_ray_dataset(model_eval_results_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8dcd9b-330a-4154-b457-85a9f7207c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6404ee-afde-4c3e-a9bd-c11d78346645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_df = predictions_df.with_column(\n",
    "    \"predictions\",\n",
    "    predictions_df[\"predictions\"].apply(lambda x: x.argmax(), return_dtype=int)\n",
    ")\n",
    "predictions_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2165ce3-a5e2-4336-a756-3a839cdfc35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_df = predictions_df.with_column(\n",
    "    \"correct\",\n",
    "    (predictions_df[\"predictions\"] == predictions_df[\"label\"]).cast(int)\n",
    ")\n",
    "predictions_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f673c-45eb-4769-9063-b55b6c6e383d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_df.groupby(\"label\").sum(\"correct\").sort(\"label\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b516b14-73bb-4a95-ad8b-f2ce426905ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
