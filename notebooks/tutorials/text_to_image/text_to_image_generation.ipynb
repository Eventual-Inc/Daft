{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78db424a-96b5-46f3-bd32-484f5c6b92a3",
   "metadata": {},
   "source": [
    "# Generating Images from Text with Stable Diffusion\n",
    "\n",
    "In this tutorial, we will be using a model called Stable Diffusion to generate images from text. We will explore how to use GPUs with Daft to accelerate computations.\n",
    "\n",
    "To run this tutorial:\n",
    "\n",
    "1. You will need to create a Huggingface account and an access token so that you can access the Stable Diffusion model: https://huggingface.co/docs/hub/security-tokens\n",
    "\n",
    "2. You will need access to a GPU. If you are on Google Colab, you may switch to a GPU runtime by going to the menu `Runtime -> Change runtime type -> Hardware accelerator -> GPU -> Save`.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019805d9-4e9f-4306-8f18-a565cb1e8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install getdaft\n",
    "!pip install Pillow torch diffusers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6ff3c-2093-4395-ad0f-1543b2481524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace with your auth token as a string\n",
    "# See: https://huggingface.co/docs/hub/security-tokens\n",
    "HUGGINGFACE_AUTH_TOKEN = os.getenv(\"HUGGINGFACE_AUTH_TOKEN\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da65a96-e4fe-4795-92d0-a5e631b58e33",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "\n",
    "First, let's download a Parquet file containing some of the data that was used to train the Stable Diffusion model. This data is available on Huggingface as well, and we simply download the file to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f574451-9a5f-4795-8aa2-58ce0892411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "PARQUET_URL = \"https://huggingface.co/datasets/ChristophSchuhmann/improved_aesthetics_6.5plus/resolve/main/data/train-00000-of-00001-6f24a7497df494ae.parquet\"\n",
    "PARQUET_PATH = \"laion_improved_aesthetics_6_5.parquet\"\n",
    "\n",
    "if not os.path.exists(PARQUET_PATH):\n",
    "    with open(PARQUET_PATH, \"wb\") as f:\n",
    "        response = urllib.request.urlopen(PARQUET_URL)\n",
    "        f.write(response.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c4950-ca59-4aa9-ad82-6cfaa516850a",
   "metadata": {},
   "source": [
    "Now we can load this Parquet file into Daft and peek at the data like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806451f8-68af-462a-af7b-ff5480425a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft import DataFrame, col, udf\n",
    "\n",
    "parquet_df = DataFrame.from_parquet(PARQUET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3b619-beaf-465e-83f2-5ab71638dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257cd91-db90-4803-afd9-9fdf571cf755",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_df = parquet_df.select(col(\"URL\"), col(\"TEXT\"), col(\"AESTHETIC_SCORE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28047df-bf05-47df-b4d4-3507a8f7d2ac",
   "metadata": {},
   "source": [
    "## Downloading Images\n",
    "\n",
    "Like many datasets, instead of storing the actual images in the dataset's files it looks like the Dataset authors have instead opted to store a URL to the image.\n",
    "\n",
    "Let's use Daft's builtin functionality to download the images and open them as PIL Images - all in just a few lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5cd84-4526-4a91-9fd5-f4e78f35965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "parquet_df_with_long_strings = parquet_df.where(col(\"TEXT\").str.length() > 50)\n",
    "images_df = parquet_df_with_long_strings.with_column(\n",
    "    \"image\",\n",
    "    # Download the images, then load them as PIL.Images if the download was successful\n",
    "    col(\"URL\").url.download().apply(lambda data: PIL.Image.open(io.BytesIO(data)) if data is not None else None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1361728-8b1a-4e6e-9632-ddd17cad948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "images_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa31d0-bcaa-44c6-8a5b-8b1b6ff51f93",
   "metadata": {},
   "source": [
    "## Running a model (without a GPU)\n",
    "\n",
    "We can run the Huggingface model without a GPU. Note that the next cell will take a while to run - almost 5 minutes! As such, we have commented out the line of code that runs the image generation, but you may run the code simply by uncommenting the last line of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd603b-86c1-4b77-94ea-6025cd298da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "@udf(return_type=PIL.Image.Image)\n",
    "class GenerateImageFromText:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = DiffusionPipeline.from_pretrained(\n",
    "            \"CompVis/stable-diffusion-v1-4\",\n",
    "            use_auth_token=HUGGINGFACE_AUTH_TOKEN,\n",
    "        )\n",
    "\n",
    "    def __call__(self, text_col, num_steps=5):\n",
    "        return [self.pipeline(t, num_inference_steps=num_steps)[\"sample\"][0] for t in text_col]\n",
    "\n",
    "# Uncomment the following line to run the cell which will take about 5 minutes.\n",
    "# %time images_df.with_column(\"generated_image\", GenerateImageFromText(col(\"TEXT\"), num_steps=1)).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad627801-b3f7-46fb-8415-579c9118cb78",
   "metadata": {},
   "source": [
    "That took a long time, even when we only ran 5 steps of the model on only a single image (CompVis recommends running 50 steps - notice that the generated image is not very good). If you are on the default Google Colab runtime, this would have taken almost 5 minutes! Running it on more images and more steps would take too long.\n",
    "\n",
    "Let's see how we can tell Daft that this UDF requires a GPU, and include a step to load our model on the GPU so that it runs much faster. Note that **the following cell will throw an error if you are not running on a machine with a GPU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86781713-b2cc-469a-8764-864d20362418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# Tell Daft to use N number of GPUs with num_gpus=N\n",
    "@udf(return_type=PIL.Image.Image, num_gpus=1)\n",
    "class GenerateImageFromTextGPU:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pipeline = DiffusionPipeline.from_pretrained(\n",
    "            \"CompVis/stable-diffusion-v1-4\",\n",
    "            use_auth_token=HUGGINGFACE_AUTH_TOKEN,\n",
    "        )\n",
    "        # 1 GPU is now available to your code and can be used as per usual in your libraries such as PyTorch\n",
    "        self.pipeline = self.pipeline.to(\"cuda:0\")\n",
    "\n",
    "    def __call__(self, text_col, num_steps=5):\n",
    "        return [self.pipeline(t, num_inference_steps=num_steps)[\"sample\"][0] for t in text_col]\n",
    "\n",
    "%time images_df.with_column(\"generated_image\", GenerateImageFromTextGPU(col(\"TEXT\"), num_steps=30)).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b390c",
   "metadata": {},
   "source": [
    "Running the model on a GPU instead lets us run 30 steps in a minute. The generated image now looks much better, and we have a ~30x speedup from just using CPUs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
