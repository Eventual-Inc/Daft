{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b14abf5-a183-4bfb-9b15-a9a54b744fce",
   "metadata": {},
   "source": [
    "# Quickstart with DaFt\n",
    "\n",
    "In this Quickstart tutorial, we will be using the Fashion MNIST dataset to demonstrate some of DaFt's core functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec0b84-5123-4868-9597-2ee511c64c3c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Download and extract required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600bf79-360c-4a3c-ac0f-6735784989bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "URL = \"https://dax-cdn.cdn.appdomain.cloud/dax-fashion-mnist/1.0.2/fashion-mnist.tar.gz\"\n",
    "TARFILE_PATH = \"fashion-mnist.tar.gz\"\n",
    "urllib.request.urlretrieve(URL, TARFILE_PATH)\n",
    "with tarfile.open(TARFILE_PATH, \"r:gz\") as tar:\n",
    "    tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3b5ad-1442-427d-899a-a23838d60951",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CSV_PATH = \"fashion-mnist_test.csv\"\n",
    "TRAIN_CSV_PATH = \"fashion-mnist_train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b5128-99c2-49dd-b624-6e4b21275959",
   "metadata": {},
   "source": [
    "## Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63a3ad-0e0a-4ab3-9cc0-cbec8bdd0632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft import DataFrame, col, udf\n",
    "\n",
    "images_df = DataFrame.from_csv(TRAIN_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a71adf-3b2e-4ec5-a0d2-34ad8eec734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7872e3-9860-4867-8a8c-61a69f69e334",
   "metadata": {},
   "source": [
    "## Create Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af857589-b28a-4ee0-91cd-dc7a01ff4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "columns = [col(f\"pixel{i}\") for i in range(1, 785)]\n",
    "\n",
    "@udf(return_type=np.ndarray)\n",
    "def pixels_to_np_array(*pixels):\n",
    "    return np.stack(pixels).T\n",
    "    \n",
    "images_df = images_df.select(col(\"label\"), pixels_to_np_array(*columns).alias(\"img_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2593f12-8343-4246-bd75-ab213e18b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5b29a-9ec9-4e69-8461-846a768716aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = images_df.with_column(\"reshaped_array\", col(\"img_array\").as_py(np.ndarray).reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd5ff9-2131-4219-a9fd-4aa362bf12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d2664-12d8-4964-85cd-a67f8fee1384",
   "metadata": {},
   "source": [
    "## Create Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961dc50-2880-4320-beb1-3d1e21e60d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "@udf(return_type=Image.Image)\n",
    "def arr_to_img(np_arrs):\n",
    "    return [Image.fromarray(arr.astype(np.uint8)) for arr in np_arrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585303a-7c83-4a31-afbb-461c951481f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = images_df.with_column(\"image\", arr_to_img(col(\"reshaped_array\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b655ed-13aa-4764-acd4-a00beb91ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ea72e-be32-4c61-a516-667838f61b1e",
   "metadata": {},
   "source": [
    "## Filtering a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a10930-2583-4d0b-93d7-016aeecc6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.where(col(\"label\") == 8).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7e6774-9fb7-4827-a324-c116c8c812e1",
   "metadata": {},
   "source": [
    "## Running a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff43066-8a42-4773-974f-160ca4a9bc49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "\n",
    "@udf(return_type=int)\n",
    "class ClassifyImages:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._model = AutoModelForImageClassification.from_pretrained(\"arize-ai/resnet-50-fashion-mnist-quality-drift\", torch_dtype=torch.double)\n",
    "\n",
    "    def __call__(self, images):\n",
    "        converted_image_arrays = np.array([np.array(img.convert('RGB')) for img in images])\n",
    "        converted_image_arrays = np.moveaxis(converted_image_arrays, 3, 1)  # (BATCH, X, Y, CHANNEL) -> (BATCH, CHANNEL, X, Y)\n",
    "        converted_image_arrays = converted_image_arrays / 255\n",
    "        classifications = self._model(torch.from_numpy(converted_image_arrays).double()).logits\n",
    "        return classifications.detach().numpy().argmax(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fd9f8-a231-44fb-a519-0288f670a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_images_df = images_df.with_column(\"model_classification\", ClassifyImages(col(\"image\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba0444-1f05-440d-b0db-be7ae9b973ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_images_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a8cd6-518f-434a-9902-10db38740185",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_images_df.where(col(\"label\") == 8).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef6cd2-210d-46ca-a9ba-e39bda859f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_COUNT = 1000\n",
    "\n",
    "@udf(return_type=int)\n",
    "def matched(labels, model_classifications):\n",
    "    return (labels == model_classifications).astype(int)\n",
    "\n",
    "@udf(return_type=float)\n",
    "def to_float(ints):\n",
    "    return ints.astype(float)\n",
    "\n",
    "ground_truth_counts = classified_images_df \\\n",
    "    .limit(SAMPLE_COUNT) \\\n",
    "    .with_column(\"matched\", matched(col(\"label\"), col(\"model_classification\"))) \\\n",
    "    .with_column(\"not_matched\", abs(col(\"matched\") - 1)) \\\n",
    "    .groupby(col(\"label\")) \\\n",
    "    .agg([\n",
    "        (col(\"matched\").alias(\"true_positive\"), \"sum\"),\n",
    "        (col(\"not_matched\").alias(\"false_negative\"), \"sum\"),\n",
    "    ])\n",
    "\n",
    "prediction_counts = classified_images_df \\\n",
    "    .limit(SAMPLE_COUNT) \\\n",
    "    .with_column(\"matched\", matched(col(\"label\"), col(\"model_classification\"))) \\\n",
    "    .with_column(\"not_matched\", abs(col(\"matched\") - 1)) \\\n",
    "    .groupby(col(\"model_classification\")) \\\n",
    "    .agg([\n",
    "        (col(\"matched\").alias(\"true_positive\"), \"sum\"),\n",
    "        (col(\"not_matched\").alias(\"false_positive\"), \"sum\"),\n",
    "    ])\n",
    "\n",
    "precision_recall = ground_truth_counts \\\n",
    "    .join(\n",
    "        prediction_counts,\n",
    "        left_on=col(\"label\"),\n",
    "        right_on=col(\"model_classification\"),\n",
    "    ) \\\n",
    "    .with_column(\"precision\", to_float(col(\"true_positive\")) / (col(\"true_positive\") + col(\"false_positive\"))) \\\n",
    "    .with_column(\"recall\", to_float(col(\"true_positive\")) / (col(\"true_positive\") + col(\"false_negative\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e344364-a168-4911-9d88-9fac27e72966",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e9dd6-4cce-4fec-ba81-f884aea75bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296eee1-7153-4e71-bdb2-f9a15b822ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
